# Econometrics II Final Project

This repository contains the final project for the Econometrics II course. The goal of this project is to build a fully-documented, reproducible, and well-organized data scraping pipeline using a public API of choice.

## Project Structure

```
your-repo/
├── README.md
├── .gitignore
├── requirements.txt
├── code/
│   └── scrape_comments.py
└── data/
    └── dataset.csv
```

- `README.md`: This file, which documents the purpose, structure, and usage of the project.
- `.gitignore`: Ensures that sensitive files such as `.env` or credential files are not tracked.
- `requirements.txt`: Contains the exact versions of all libraries needed to run the project.
- `code/scrape_comments.py`: The Python script that connects to the public API, retrieves the data, and stores it.
- `data/dataset.csv`: Final dataset generated by the pipeline.

## Purpose

The objective of this project is to implement a complete and reproducible data scraping pipeline. The pipeline connects to a public API, retrieves data, processes it into a clean format, and stores it as a dataset suitable for analysis.

## How to Use

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/your-repo.git
   cd your-repo
   ```

2. **Set up a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Set up your API credentials**
   - Create a `.env` file in the root directory with the required keys, for example:
     ```
     API_KEY=your_api_key_here
     ```

4. **Run the scraper**
   ```bash
   python code/scrape_comments.py
   ```

5. **Final dataset**
   - The output will be saved in `data/dataset.csv`. The dataset contains at least 500 rows and includes metadata identifying the data source (such as a title, URL, or unique ID).

## Reproducibility

This project includes a `requirements.txt` file that ensures the environment can be reproduced exactly. All dependencies are explicitly used and version-pinned.

Example:
```
requests==2.31.0
pandas==2.2.2
python-dotenv==1.0.1
```

## Notes

- The code is written in compliance with PEP-8.
- Sensitive credentials are handled securely using environment variables.
- The dataset includes a column to identify the source of each data point.

## Submission

This project is submitted as a public GitHub repository in accordance with the course instructions.

**Deadline:** May 31, 2025
